# Basics
## 2023-02-04 Sat
### 카프카의 시작
* 카프카는 LinkedIn이 데이터 수집과 분배 아키텍쳐가 파편화되어 운영 상에 어려움을 겪으면서 시작되었다.
* 크게 데이터를 생성하는 소스 애플리케이션과 이를 소비하는 타겟 애플리케이션으로 분류했을 때, 아키텍쳐가 복잡해질수록 데이터 전송 라인의 관리는 어려워진다.
  * 이 경우, **타겟 애플리케이션 중 하나에 장애가 발생하면 이와 관련이 있는 모든 소스 애플리케이션이 함께 오동작**하게 된다.
* LinkedIn은 이러한 문제를 해결하기 위해 많은 상용 프레임워크와 오픈 소스를 사용해보았지만, 결과적으로 데이터 파이프라인의 복잡성을 낮추지는 못했다.
  * 이 과정에서 다양한 메시징 플랫폼과 ETL 도구를 적용했지만, 결과는 항상 같았다.
* 결국 LinkedIn에서는 이러한 복잡성을 해결하기 위한 새로운 시스템을 개발하였고, 카프카는 각 애플리케이션 간의 연결을 중앙집중적으로 관리하며 시작되었다.

### 카프카와 FIFO
* 카프카의 내부에서 논리적으로 관리되는 파티션의 동작은 FIFO 방식으로 동작하는 큐와 유사하다.
  * 정확히는 **카프카가 내부적으로 토픽을 관리하며, 각각의 토픽은 다시 하나 이상의 파티션으로 구성**될 수 있다.
  * 때문에 **소스 애플리케이션은 타겟 애플리케이션에 신경쓰기 보다는 일단 데이터를 카프카에 적재**하는 방식으로 동작하게 된다.
* **파티션에 데이터를 삽입하는 소스 애플리케이션은 프로듀서이며 큐로부터 데이터를 소비하는 타겟 애플리케이션은 컨슈머로 지칭**될 수 있다.
* 이렇듯 **프로듀서에 의해 카프카 토픽에 삽입되는 데이터는 토픽을 구성하는 파티션 중 하나에 삽입**된다.
  * 반면, 컨슈머는 자신이 구독한 여러 파티션으로부터 데이터를 가져가 적절한 방식으로 소비한다.
  * 이 때, **중요한 것은 컨슈머가 파티션으로부터 데이터를 조회하더라도 조회된 파티션의 데이터는 삭제되지 않는 다는 특징**이다.
  * 때문에 **FIFO 구조로 인해 데이터를 조회했더라도, 해당 데이터는 다른 방식으로 다시 소비될 가능성**이 열려있다.
* **임의의 컨슈머가 데이터를 읽어들인 기록은 카프카 내부적으로 관리되며, 이러한 기록을 커밋이라는 용어로 지칭**한다.
  * 때문에 커밋을 토대로 컨슈머는 파티션의 어느 지점까지 조회했고, 어디부터 조회해야할지 알 수 있다.